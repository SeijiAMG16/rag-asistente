#!/usr/bin/env python3
"""
Prueba del Sistema RAG Avanzado con Modelos LLM Potentes
Utiliza Groq API con Llama 3.3 70B para anÃ¡lisis inteligente
"""

import os
import sys

# AÃ±adir el directorio backend al path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Configurar variables de entorno
from dotenv import load_dotenv
load_dotenv()

def test_advanced_rag():
    """
    Prueba el sistema RAG con modelos LLM potentes
    """
    print("ğŸ”¥ PRUEBA DEL SISTEMA RAG AVANZADO")
    print("ğŸ¤– Modelo: Groq Llama 3.3 70B")
    print("=" * 60)
    
    # Importar funciones de RAG
    from utils.rag_utils import perform_semantic_search, generate_rag_response
    
    # Consultas de prueba mÃ¡s especÃ­ficas
    test_queries = [
        "Â¿CuÃ¡les son las causas del racismo en el PerÃº segÃºn los documentos?",
        "Â¿CÃ³mo se manifiesta la discriminaciÃ³n social en la sociedad peruana?",
        "Â¿QuÃ© caracterÃ­sticas definen la identidad cultural peruana?",
        "Â¿CuÃ¡les son los principales problemas de la clase media en el PerÃº?",
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nğŸ” CONSULTA {i}: {query}")
        print("-" * 80)
        
        try:
            # BÃºsqueda semÃ¡ntica
            print("ğŸ“š Buscando documentos relevantes...")
            search_results = perform_semantic_search(query, top_k=4)
            
            if not search_results:
                print("âŒ No se encontraron documentos relevantes")
                continue
                
            print(f"âœ… Encontrados {len(search_results)} documentos relevantes")
            
            # Mostrar fuentes encontradas con scores
            print("\nğŸ“‹ FUENTES IDENTIFICADAS:")
            for j, result in enumerate(search_results, 1):
                score = result['similarity_score']
                archivo = result['archivo']
                print(f"   {j}. {archivo}")
                print(f"      ğŸ“Š Relevancia: {score:.3f}")
            
            # Generar respuesta con LLM avanzado
            print(f"\nğŸ§  Analizando con Llama 3.3 70B...")
            response = generate_rag_response(query, search_results)
            
            print(f"\nğŸ’¬ ANÃLISIS INTELIGENTE:")
            print("=" * 40)
            print(response)
            print("=" * 40)
            
        except Exception as e:
            print(f"âŒ Error procesando consulta: {str(e)}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "ğŸ”„"*80)
        
        # Pausa entre consultas
        input("Presiona Enter para continuar con la siguiente consulta...")

def verify_api_keys():
    """
    Verifica que las API keys estÃ©n configuradas
    """
    print("ğŸ” VERIFICANDO CONFIGURACIÃ“N DE API KEYS:")
    print("-" * 50)
    
    apis = {
        "GROQ": os.getenv("GROQ_API_KEY"),
        "TOGETHER": os.getenv("TOGETHER_API_KEY"),
        "GEMINI": os.getenv("GEMINI_API_KEY"),
        "OPENAI": os.getenv("OPENAI_API_KEY"),
    }
    
    for api_name, api_key in apis.items():
        if api_key:
            masked_key = api_key[:8] + "..." + api_key[-4:]
            print(f"âœ… {api_name}: {masked_key}")
        else:
            print(f"âšª {api_name}: No configurado")
    
    print()

if __name__ == "__main__":
    print("ğŸš€ SISTEMA RAG AVANZADO - PRUEBA COMPLETA")
    print("ğŸ”¥ ANÃLISIS INTELIGENTE CON LLM POTENTES")
    print("=" * 60)
    
    # Verificar configuraciÃ³n
    verify_api_keys()
    
    # Verificar base de datos
    try:
        from utils.rag_utils import initialize_rag_components
        model, client, collection = initialize_rag_components()
        count = collection.count()
        print(f"ğŸ“š Base de datos ChromaDB: {count} documentos cargados")
        print()
    except Exception as e:
        print(f"âŒ Error verificando base de datos: {e}")
        sys.exit(1)
    
    # Iniciar pruebas
    test_advanced_rag()
    
    print("\nâœ… PRUEBA COMPLETADA")
    print("ğŸ¯ Sistema RAG avanzado funcionando correctamente")